{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5763f02f-60fc-4a71-9d2f-294be676bb5f",
   "metadata": {},
   "source": [
    "# Подготовка, импорты библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58dbf931-3b09-4b06-83dc-7918321a9645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lakeo\\AppData\\Local\\Temp\\ipykernel_16668\\3576183778.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f24218cb-77c0-4bf4-9f7f-c854021dfd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd74bbd-1ea6-4bf0-805b-5818b069713a",
   "metadata": {},
   "source": [
    "# Сбор датасетов для обучения, валидации и теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19946b48-fe0f-4f88-a1c2-76d5a64016a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     filename  class_number\n",
      "0  000000.png            18\n",
      "1  000001.png            18\n"
     ]
    }
   ],
   "source": [
    "#указываем путь к данным\n",
    "DATA_PATH = \"./data/\"\n",
    "TRAIN_ANN_PATH = DATA_PATH + 'train.csv'\n",
    "\n",
    "#читаем аннотацию\n",
    "train_df = pd.read_csv(TRAIN_ANN_PATH)\n",
    "print(train_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "336b0933-25bc-480d-b7e1-913ab14e84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadSignDataset(data.Dataset):\n",
    "  \"\"\"Road Signs dataset class.\n",
    "\n",
    "    Arguments:\n",
    "        root (str): path to images\n",
    "        imlist - pandas DataFrame with columns file_name, class\n",
    "        transform - torchvision transform applied to every image\n",
    "    \"\"\"\n",
    "  def __init__(self, root, flist, transform=None):\n",
    "        self.root   = root\n",
    "        self.imlist = flist \n",
    "        self.transform = transform\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        #берем строку из пришедшего df по index\n",
    "        impath, target = self.imlist.loc[index]\n",
    "\n",
    "        #собираем полное имя картинки\n",
    "        full_imname = os.path.join(self.root, impath)\n",
    "\n",
    "        if not os.path.exists(full_imname):\n",
    "            print('No file ', full_imname)\n",
    "            pass\n",
    "\n",
    "        img = Image.open(full_imname).convert('RGB')\n",
    "\n",
    "        #применяем к изображению выбранное преобразование (аугментацию)\n",
    "        img = self.transform(img)\n",
    "\n",
    "        #на выход отдаём img, target - нужны для обучения и валидации\n",
    "        return img, target, impath\n",
    "\n",
    "  #метод возвращает длину датасета - просто как длину подаваемого dataframe\n",
    "  def __len__(self):\n",
    "        return len(self.imlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f19a6e9-a3d3-4d9d-8745-5bc8dfa69066",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadSignTestDataset(data.Dataset):\n",
    "  \"\"\"Road Signs Test dataset class.\n",
    "\n",
    "    Arguments:\n",
    "        root (str): path to images\n",
    "        imlist - list of file_name\n",
    "        transform - torchvision transform applied to every image\n",
    "    \"\"\"\n",
    "  def __init__(self, root, flist=None, transform=None):\n",
    "        self.root   = root\n",
    "        \n",
    "        if flist is not None:\n",
    "            self.imlist = flist\n",
    "        else:\n",
    "            self.imlist = []\n",
    "            for filename in os.listdir(self.root):\n",
    "                if filename[filename.rfind(\".\") + 1:] in ['jpg', 'jpeg', 'png']:\n",
    "                    self.imlist.append(filename)\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "\n",
    "        impath = self.imlist[index]\n",
    "\n",
    "        #собираем полное имя картинки\n",
    "        full_imname = os.path.join(self.root, impath)\n",
    "\n",
    "        if not os.path.exists(full_imname): #если нет такой, ругаемся\n",
    "            print('No file ', full_imname)\n",
    "            pass\n",
    "\n",
    "        #Сразу используем PIL тк torchvision.transforms работает с PIL Image (https://pytorch.org/docs/stable/torchvision/transforms.html)\n",
    "        img = Image.open(full_imname).convert('RGB')\n",
    "\n",
    "        #применяем к изображению выбранное преобразование (аугментацию)\n",
    "        img = self.transform(img)\n",
    "\n",
    "        #на выход отдаём img - нужны для обучения и валидации\n",
    "        return img, impath\n",
    "\n",
    "  #метод возвращает длину датасета - просто как длину подаваемого dataframe\n",
    "  def __len__(self):\n",
    "        return len(self.imlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83978f9d-0a3c-4121-90ed-0219ab3780b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#преобразования для train и val\n",
    "transform_for_train_and_val = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "#преобразования для test, для старта те же\n",
    "transform_for_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "#датафреймы\n",
    "train, val = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "#нам нужно будет обращаться по индексу, так что делаем reset\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "val.reset_index(inplace=True, drop=True)\n",
    "\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20c3629b-73a2-439b-a81c-55395bf9e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = RoadSignDataset(root='./data/train', flist=train, transform=transform_for_train_and_val)\n",
    "valset = RoadSignDataset(root='./data/train', flist=val, transform=transform_for_train_and_val)\n",
    "testset = RoadSignTestDataset(root='./data/test', flist=None, transform=transform_for_train_and_val)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b33454-09db-4cab-8b3c-c66d3daebf4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b814b-b9ff-4e94-82fd-771699d935a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
